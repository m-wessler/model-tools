{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, os\n",
    "import pickle\n",
    "import cfgrib\n",
    "import pygrib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from multiprocessing import get_context\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "mp_use_cores = 32\n",
    "use_era_scaler = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gfs0p25'\n",
    "archive = '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/archive/'\n",
    "mlmodel_dir = '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/output/slr_models/all_dev/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = datetime(2020, 1, 1, 0, 0)\n",
    "date_fmt = '%Y%m%d'\n",
    "datetime_fmt = '%Y%m%d%H'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_gfs(f):\n",
    "    \n",
    "    # print('Reading %s'%os.path.basename(f))\n",
    "\n",
    "    datasets = cfgrib.open_datasets(f)\n",
    "\n",
    "    keep_keys = ['tp', 'q', 't', 'u', 'v', 'absv', 'w', 'gh', 'r', 'd', \n",
    "                  'u10', 'v10', 'u100', 'v100', 't2m', 'd2m', \n",
    "                  'cape', 'prmsl', 'sp', 'orog', 'hpbl']\n",
    "\n",
    "    sfc, iso = [], []\n",
    "\n",
    "    for ds in datasets:\n",
    "\n",
    "        key_match = np.array(list(ds.data_vars))[np.isin(list(ds.data_vars), keep_keys)]\n",
    "\n",
    "        if len(key_match) > 0:\n",
    "\n",
    "            dims = ds.dims.keys()\n",
    "            coords = ds[key_match].coords\n",
    "\n",
    "            if ('heightAboveGround' in coords) & ('heightAboveGround' not in dims):\n",
    "                sfc.append(ds[key_match].drop('heightAboveGround'))\n",
    "\n",
    "            elif 'isobaricInhPa' in coords:\n",
    "                iso.append(ds[key_match])\n",
    "\n",
    "            elif (('surface' in coords)|('meanSea' in coords)):\n",
    "                sfc.append(ds[key_match])\n",
    "\n",
    "            elif 'prmsl' in list(ds.data_vars):\n",
    "                sfc.append(ds['prmsl'])\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    sfc = xr.merge(sfc).drop('t')\n",
    "    iso = xr.merge(iso).rename({'isobaricInhPa':'level'})\n",
    "    iso = iso.sel(level=iso.level[::-1])\n",
    "\n",
    "    sfc['longitude'] = sfc['longitude'] - 360\n",
    "    iso['longitude'] = iso['longitude'] - 360\n",
    "    \n",
    "    return [sfc, iso]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = glob(archive + init.strftime(date_fmt) + '/models/%s/*%s*.grib2'%(model, init.strftime(datetime_fmt)))[1:]\n",
    "\n",
    "with get_context('fork').Pool(mp_use_cores) as p:\n",
    "    returns = p.map(ingest_gfs, flist, chunksize=1)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    \n",
    "returns = np.array(returns, dtype=object)\n",
    "sfc, iso = returns[:, 0], returns[:, 1]\n",
    "    \n",
    "iso = xr.concat(iso, dim='valid_time').drop('time').rename({'valid_time':'time'}).sortby('time')\n",
    "sfc = xr.concat(sfc, dim='valid_time').drop('time').rename({'valid_time':'time'}).sortby('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = iso['u'], iso['v']\n",
    "wdir = 90 - np.degrees(np.arctan2(-v, -u))\n",
    "wdir = xr.where(wdir <= 0, wdir+360, wdir)\n",
    "wdir = xr.where(((u == 0) & (v == 0)), 0, wdir)\n",
    "\n",
    "iso['dir'] = wdir\n",
    "iso['spd'] = np.sqrt(u**2 + v**2)\n",
    "\n",
    "for hgt in [10, 100]:\n",
    "    \n",
    "    u, v = sfc['u%d'%hgt], sfc['v%d'%hgt]\n",
    "    wdir = 90 - np.degrees(np.arctan2(-v, -u))\n",
    "    wdir = xr.where(wdir <= 0, wdir+360, wdir)\n",
    "    wdir = xr.where(((u == 0) & (v == 0)), 0, wdir)\n",
    "    \n",
    "    sfc['dir%dm'%hgt] = wdir\n",
    "    sfc['spd%dm'%hgt] = np.sqrt(u**2 + v**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orog = sfc.orog\n",
    "gh = iso.gh\n",
    "\n",
    "lowest_level = np.full(orog.shape, fill_value=np.nan)\n",
    "lowest_level_index = np.full(orog.shape, fill_value=np.nan)\n",
    "\n",
    "for i, level in enumerate(iso['level']):\n",
    "    \n",
    "    lev_gh = gh.sel(level=level)\n",
    "    lowest_level = xr.where(orog >= lev_gh, level.values, lowest_level)\n",
    "    lowest_level_index = xr.where(orog >= lev_gh, i, lowest_level_index)\n",
    "    \n",
    "lowest_level_index = xr.where(np.isnan(lowest_level), 0, lowest_level_index)\n",
    "lowest_level = xr.where(np.isnan(lowest_level), 1000, lowest_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "match_rename = {'absv':'vo', 'gh':'z', 'hpbl':'blh', 'prmsl':'msl', 'tp':'swe_mm',\n",
    "               'u10':'u10m', 'v10':'v10m', 'u100':'u100m', 'v100':'v100m'}\n",
    "\n",
    "# Loop over each variable in the xarray\n",
    "for ds in [iso, sfc.drop('orog')]:\n",
    "    \n",
    "    for var_name in ds.data_vars:\n",
    "        \n",
    "        new_var_name = match_rename[var_name] if var_name in match_rename.keys() else var_name\n",
    "        print('Reducing (%s) to %s index level AGL'%(var_name, new_var_name))\n",
    "\n",
    "        var = ds[var_name]\n",
    "\n",
    "        if 'level' in var.coords:\n",
    "\n",
    "            for i in np.arange(10):\n",
    "\n",
    "                var_agl = np.full(shape=(orog.shape), fill_value=np.nan)\n",
    "\n",
    "                for j, level in enumerate(iso['level']):\n",
    "\n",
    "                    var_agl = xr.where(lowest_level_index+i == j, var.isel(level=j), var_agl)\n",
    "\n",
    "                    # Record the levels used, should match lowest_level array, sanity check\n",
    "                    # var_agl[i, :, :] = xr.where(lowest_level_index+i == j, level, var_agl[i, :, :])\n",
    "\n",
    "                # We could ho ahead and append to the pandas dataframe here \n",
    "                # at the completion of each level (_01agl, _02agl...)\n",
    "                # We will have to use [(time), lat, lon] as a multiindex\n",
    "                var_agl = xr.DataArray(var_agl, \n",
    "                     dims=['time', 'latitude', 'longitude'], \n",
    "                     coords={'time':ds['time'],\n",
    "                             'latitude':ds['latitude'], \n",
    "                             'longitude':ds['longitude']})\n",
    "\n",
    "                df.append(var_agl.to_dataframe(name='%s_%02dagl'%(new_var_name.upper(), i+1)))\n",
    "\n",
    "                del var_agl\n",
    "                gc.collect()\n",
    "\n",
    "        else:\n",
    "\n",
    "            var_agl = xr.DataArray(var.values, \n",
    "                dims=['time', 'latitude', 'longitude'], \n",
    "                coords={'time':ds['time'],\n",
    "                    'latitude':ds['latitude'], \n",
    "                     'longitude':ds['longitude']})\n",
    "\n",
    "            df.append(var_agl.to_dataframe(name='%s'%new_var_name.upper()))\n",
    "\n",
    "# SLOW!!! Is there anything we can do here??\n",
    "df = reduce(lambda left, right: pd.merge(left, right, on=['time', 'latitude', 'longitude']), df)\n",
    "df = df.rename(columns={'SWE_MM':'swe_mm'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df.to_xarray()\n",
    "ds = ds.assign_coords({'init':init})\n",
    "ds.to_netcdf(outpath + init.strftime(datetime_fmt) + '.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
