{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "\n",
    "from subprocess import run, PIPE\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ERA5 Profile: 40.4561, -112.52351, 1980, 2020\n"
     ]
    }
   ],
   "source": [
    "lat, lon, start, end = 40.4561, -112.52351, 1980, 2020 #sys.argv[1:]\n",
    "lat, lon = float(lat), float(lon)\n",
    "start, end = int(start), int(end)\n",
    "\n",
    "print('Creating ERA5 Profile: {}, {}, {}, {}'.format(\n",
    "    lat, lon, start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "isodir = '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/era5/iso/'\n",
    "sfcdir = '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/era5/sfc/'\n",
    "profdir = '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/era5/profiles/disagg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "isokeys = ['q', 't', 'u', 'v', 'vo', 'w', 'z', 'r']\n",
    "sfckeys = ['100u', '100v', '10u', '10v', '2d', '2t', 'blh', 'cape', 'msl', 'sp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERA5 profile at gridpoint: 40.50, -112.50\n"
     ]
    }
   ],
   "source": [
    "sample = xr.open_dataset('./era5_iso_sample.nc')\n",
    "a = abs(sample['latitude']-lat)+abs(sample['longitude']-360-lon)\n",
    "yi, xi = np.unravel_index(a.argmin(), a.shape)\n",
    "\n",
    "lat = sample.isel(latitude=yi, longitude=xi)['latitude']\n",
    "lon = sample.isel(latitude=yi, longitude=xi)['longitude'] - 360\n",
    "print('ERA5 profile at gridpoint: %.2f, %.2f'%(lat, lon))\n",
    "\n",
    "def get_year(year, key, levelset):\n",
    "    \n",
    "    # print('Working on: %s %04d'%(key, year))\n",
    "        \n",
    "    year_data = []\n",
    "    for month in np.arange(1, 2+1):\n",
    "        \n",
    "        print('Working on: %s %04d %02d'%(key, year, month))\n",
    "        \n",
    "        datadir = isodir if levelset == 'iso' else sfcdir\n",
    "        date_dir = datadir + '%04d%02d'%(year, month)\n",
    "\n",
    "        flist = sorted(glob(date_dir + '/*_%s.*'%key))\n",
    "        # flist = flist[0] if len(flist) == 1 else flist\n",
    "        \n",
    "        month_data = xr.open_mfdataset(flist, concat_dim='time', drop_variables=['utc_date'], parallel=True,\n",
    "                                  decode_cf=True, decode_times=True, decode_coords=False,\n",
    "                                 ).isel(latitude=yi, longitude=xi).drop(['latitude', 'longitude'])\n",
    "        \n",
    "        try:\n",
    "            if levelset == 'iso':\n",
    "                month_data = month_data.chunk({'time':month_data[key.upper()].shape[0]*1, \n",
    "                                 'level':month_data[key.upper()].shape[1]*1}).load()\n",
    "            else:\n",
    "                month_data = month_data.chunk({'time':month_data[key.upper()].shape[0]*1,}).load()\n",
    "        except:\n",
    "            raise\n",
    "            print('Failed: %04d %02d'%(year, month))\n",
    "        \n",
    "        else:\n",
    "            month_data.attrs = {}\n",
    "            year_data.append(month_data)\n",
    "\n",
    "    try:\n",
    "        year_data = xr.concat(year_data, dim='time')\n",
    "        year_data = year_data#.chunk({'time':year_data[key.upper()].shape[0],\n",
    "                             #   'level':year_data[key.upper()].shape[1]})\n",
    "    except:\n",
    "        return None\n",
    "    else:\n",
    "        return year_data#.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: cape 1990 01\n",
      "Working on: cape 1990 02\n",
      "Working on: cape 1991 01\n",
      "Working on: cape 1991 02\n",
      "Working on: cape 1992 01\n",
      "Working on: cape 1992 02\n",
      "Working on: cape 1993 01\n",
      "Working on: cape 1993 02\n",
      "Working on: cape 1994 01\n",
      "Working on: cape 1994 02\n"
     ]
    }
   ],
   "source": [
    "mpfunc = partial(get_year, key='cape', levelset='sfc')\n",
    "\n",
    "result = [mpfunc(y) for y in np.arange(1990, 1995)]\n",
    "\n",
    "# with get_context('forkserver').Pool(len(np.arange(1990, 2001))) as p: #start, end+1)))\n",
    "#     result = p.map(mpfunc, np.arange(1990, 2001), chunksize=1)\n",
    "#     p.close()\n",
    "#     p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (latitude: 81, longitude: 113, time: 744)\n",
       "Coordinates:\n",
       "  * latitude   (latitude) float64 50.0 49.75 49.5 49.25 ... 30.5 30.25 30.0\n",
       "  * longitude  (longitude) float64 232.0 232.2 232.5 232.8 ... 259.5 259.8 260.0\n",
       "  * time       (time) datetime64[ns] 2000-01-01 ... 2000-01-31T23:00:00\n",
       "Data variables:\n",
       "    CAPE       (time, latitude, longitude) float32 dask.array<shape=(744, 81, 113), chunksize=(744, 81, 113)>\n",
       "    utc_date   (time) int32 dask.array<shape=(744,), chunksize=(744,)>\n",
       "Attributes:\n",
       "    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n",
       "    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB1 data to netCDF4.\n",
       "    NETCDF_VERSION:       4.6.1\n",
       "    CONVERSION_PLATFORM:  Linux casper05 3.10.0-693.21.1.el7.x86_64 #1 SMP We...\n",
       "    CONVERSION_DATE:      Fri Jul 26 11:45:49 MDT 2019\n",
       "    Conventions:          CF-1.6\n",
       "    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n",
       "    history:              Fri Aug 23 19:30:34 2019: ncks --no_tmp_fl -d longi...\n",
       "    NCO:                  netCDF Operators version 4.7.5 (Homepage = http://n..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.open_mfdataset('/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/era5/sfc/200001/e5.oper.an.sfc.128_059_cape.ll025sc.2000010100_2000013123.WE.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
